#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=meta_paraphrase
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=12:00:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2020
module load Python/3.8.2-GCCcore-9.3.0
module load CUDA/11.0.2-GCC-9.3.0
module load cuDNN
module load Anaconda3/2020.02


#Activate environment
source activate atcs

#run experiment
srun python maml_trainer.py --exp_name small_lr --inner_loop_lr 0.001  --query_k 16 --support_k 32 --epochs 20

