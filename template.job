#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=meta_paraphrase
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=12:00:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2020
module load Python/3.8.2-GCCcore-9.3.0
module load CUDA/11.0.2-GCC-9.3.0
module load cuDNN
module load Anaconda3/2020.02


#Activate environment
source activate atcs

#run experiment
for outer_lr in 0.0001 0.0002 0.00005
  do
    for inner_lr in 0.1 0.02 0.003
      do
          srun python maml_trainer_copy.py --exp_name "$outer_lr_$inner_lr" --inner_lr $inner_lr --outer_lr $outer_lr --epochs 3000 --clip_value 1.5 --query_k 16 --support_k 32
      done
  done

